{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PadmarajBhat/Real-Time-Analytics-on-Hadoop-Notes/blob/master/pyspark_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz4CQmBXBHml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a5ed8cc0-ba6c-4eab-c73f-2bead2d9dd3b"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 46.5MB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 54.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=d19ea4d78286dfd5a6d21f24382726ab223989e11bdec4b3db13ad75aab35c28\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1Z2TmZFBc3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7a1lSl7BrQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "19ebdf8c-17b6-400b-9dd2-7b099daa36fc"
      },
      "source": [
        "(train_x,train_y), (test_x, test_y) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ile5SMUSCA-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15f92b9b-da32-44c6-98ca-b1bb0495b3cd"
      },
      "source": [
        "train_x.shape,train_y.shape, test_x.shape, test_y.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olGC6S-bCQl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2293c214-57ce-4570-bc0b-2f2bba9f3460"
      },
      "source": [
        "pd_train= pd.DataFrame(train_x.reshape(60000,784))\n",
        "pd_test = pd.DataFrame(test_x.reshape(10000,784))\n",
        "pd_train.shape,pd_test.shape\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn-m1DHPHNAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "1fb32953-f9ff-47be-c98f-1242b18b4577"
      },
      "source": [
        "pd_train.values *.1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ5eyAGLKyPM",
        "colab_type": "text"
      },
      "source": [
        "Note that we had to multiply .1 to convert the data to float else not accepted in the tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb08ox-CCI1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "5c501593-d244-49a4-8dd0-18e66b745a71"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    #tf.keras.layers.Flatten(input_shape=(28,28))\n",
        "    tf.keras.layers.Flatten()\n",
        "    ,tf.keras.layers.Dense(256,activation=\"relu\")\n",
        "    ,tf.keras.layers.Dense(128,activation=\"relu\")\n",
        "    ,tf.keras.layers.Dense(10,activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"Adam\"\n",
        "              , loss=\"sparse_categorical_crossentropy\"\n",
        "              , metrics=['accuracy']\n",
        "             )\n",
        "\n",
        "#model.fit(train,train_y, epochs=6)\n",
        "model.fit(pd_train.values *.1,train_y,epochs=6)\n",
        "model.evaluate(test_x,test_y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0901 07:41:24.395536 140368148768640 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2816 - acc: 0.9256\n",
            "Epoch 2/6\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1232 - acc: 0.9633\n",
            "Epoch 3/6\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0966 - acc: 0.9715\n",
            "Epoch 4/6\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0807 - acc: 0.9756\n",
            "Epoch 5/6\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0696 - acc: 0.9791\n",
            "Epoch 6/6\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0611 - acc: 0.9818\n",
            "10000/10000 [==============================] - 0s 40us/sample - loss: 1.1268 - acc: 0.9658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1267635655719925, 0.9658]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPuyi6f0LKnO",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow is being fed with panda which indicates that entire data is loaded. This is not a good fit for Big Data case. We need the tensorflow to work on the RDD or Df rather than panda df. Hence spark read --> convert to panda --> tensorflow pipeline fails at the second stage. For this we have https://github.com/maxpumperla/elephas\n",
        "\n",
        "\n",
        "Elephas: Take spark dataframe and trains it for the keras model. But the example does not talk about tensorflow keras but keras independent version. Not sure if tensorflow keras supports it.\n",
        "\n",
        "Why we have to worry about tf.keras or keras as independent one ? \n",
        "  - tensorflow official supports keras and hence product would have enhancements\n",
        "  - tensorflow has distributed stratergy to support distributed training. elephas has it too but may be tensorflow is better tested one becuase of larger community of dev and tester.\n",
        "  - tensorflow has official distribution on hadoop and hence better than smaller community like elephas\n",
        "  \n",
        "  \n",
        "There was mis understanding i guess, they dont provide keras but instead they transform the keras mode. Now it has to be tested so that if the tensorflow keras model is compatible with the elephas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AbTbc-XEflr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49e2ca8a-60da-4b4d-9ad4-a41fe6495d28"
      },
      "source": [
        "!pip install elephas"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: elephas in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from elephas) (2.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from elephas) (1.12.0)\n",
            "Requirement already satisfied: hyperas in /usr/local/lib/python3.6/dist-packages (from elephas) (0.4.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from elephas) (1.14.0)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (from elephas) (2.4.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from elephas) (0.29.13)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from elephas) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->elephas) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->elephas) (1.16.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->elephas) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->elephas) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->elephas) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->elephas) (1.1.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas->elephas) (1.0.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas->elephas) (4.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas->elephas) (5.6.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas->elephas) (0.1.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas->elephas) (0.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (0.33.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (0.1.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->elephas) (0.7.1)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark->elephas) (0.10.7)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask->elephas) (0.15.5)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->elephas) (2.10.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->elephas) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->elephas) (7.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas->elephas) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas->elephas) (7.5.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas->elephas) (4.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas->elephas) (4.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas->elephas) (5.2.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas->elephas) (4.5.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas->elephas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas->elephas) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas->elephas) (4.3.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas->elephas) (1.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas->elephas) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas->elephas) (3.1.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas->elephas) (2.1.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas->elephas) (0.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas->elephas) (0.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas->elephas) (4.28.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas->elephas) (3.9.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas->elephas) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas->elephas) (2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow->elephas) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow->elephas) (41.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->elephas) (1.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas->elephas) (1.0.16)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas->elephas) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas->elephas) (5.3.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas->elephas) (3.5.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas->elephas) (4.5.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas->elephas) (0.8.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1->nbformat->hyperas->elephas) (4.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas->elephas) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas->elephas) (0.1.7)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas->elephas) (4.7.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas->elephas) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas->elephas) (0.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->hyperas->elephas) (2.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->hyperas->elephas) (17.0.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->hyperas->elephas) (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfPEsJT_xwpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27b92d4e-178c-45eb-8644-e7b782450ef6"
      },
      "source": [
        "nb_classes = 10\n",
        "\n",
        "from elephas.ml_model import ElephasEstimator\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "adam = optimizers.Adam(lr=0.01)\n",
        "opt_conf = optimizers.serialize(adam)\n",
        "\n",
        "# Initialize SparkML Estimator and set all relevant properties\n",
        "estimator = ElephasEstimator()\n",
        "estimator.setFeaturesCol(\"scaled_features\")             # These two come directly from pyspark,\n",
        "estimator.setLabelCol(\"index_category\")                 # hence the camel case. Sorry :)\n",
        "estimator.set_keras_model_config(model.to_yaml())       # Provide serialized Keras model\n",
        "estimator.set_categorical_labels(True)\n",
        "estimator.set_nb_classes(nb_classes)\n",
        "estimator.set_num_workers(1)  # We just use one worker here. Feel free to adapt it.\n",
        "estimator.set_epochs(20) \n",
        "estimator.set_batch_size(128)\n",
        "estimator.set_verbosity(1)\n",
        "estimator.set_validation_split(0.15)\n",
        "estimator.set_optimizer_config(opt_conf)\n",
        "estimator.set_mode(\"synchronous\")\n",
        "estimator.set_loss(\"categorical_crossentropy\")\n",
        "estimator.set_metrics(['acc'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElephasEstimator_8d9eee46c54f"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqx9VRyKyN08",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "24718531-dffe-49ae-a53b-df78ca0e6011"
      },
      "source": [
        "estimator.fit(train_x,train_y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-aa40f8331da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n\u001b[0;32m--> 135\u001b[0;31m                              \"but got %s.\" % type(params))\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Params must be either a param map or a list/tuple of param maps, but got <class 'numpy.ndarray'>."
          ]
        }
      ]
    }
  ]
}